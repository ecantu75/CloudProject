{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Model Using AWS SageMaker\n",
    "\n",
    "This will use the a Random Forrest regression to predict the house price. AWS SageMaker will utilize the Sci-kit-learn libraries. \n",
    "The model will be stored in a S3 Bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this section specify the sage maker object session that would allow to train and create a prediction model. Also in this section, it will setup the libraries used in the notebook, as well as the S3 buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the AWS SageMaker Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'Scikit-house'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import pickle\n",
    "import gzip\n",
    "import urllib.request\n",
    "import json\n",
    "#import mxnet as mx\n",
    "import boto3\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "## New for this Project\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "3. Download data from S3 Bucket and copy into the '/home/ec2-user/Sagemaker/data' folder. This folder in the Notebook EC2 session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-2-029880428228\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.Session().resource('s3')\n",
    "\n",
    "print (sagemaker_session.default_bucket())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3.meta.client.download_file('mlbuckethose', 'ml_data/DataForModeling.csv', '/home/ec2-user/SageMaker/data/DataForModeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the SKLearn Object\n",
    "In the appendix there is a python script file that would create fit the model using the SKLearn and the data that was downloaded from the S3 Bucket. \n",
    "This object would call the python script and run it in a training instance, that would only run during the training of the model. Once the model is fit, the compute instance will be released.\n",
    "\n",
    "1. Set the SKLearn object and set the path for the Model Creation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'sklearn-randomforest.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit The Model  \n",
    "This is the section where the model is trained and saved for future deployment.\n",
    "After the fit is complete, a model will be stored under the 'Model' Section in AWS Sage Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-scikit-learn-2019-04-08-03-12-08-484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-08 03:12:08 Starting - Starting the training job...\n",
      "2019-04-08 03:12:10 Starting - Launching requested ML instances......\n",
      "2019-04-08 03:13:37 Starting - Preparing the instances for training......\n",
      "2019-04-08 03:14:38 Downloading - Downloading input data\n",
      "2019-04-08 03:14:38 Training - Training image download completed. Training in progress.\n",
      "2019-04-08 03:14:38 Uploading - Uploading generated training model.\n",
      "\u001b[31m2019-04-08 03:14:33,873 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:33,875 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:33,887 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:34,100 sagemaker-containers INFO     Module sklearn-randomforest does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:34,100 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:34,100 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:34,100 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: sklearn-randomforest\n",
      "  Running setup.py bdist_wheel for sklearn-randomforest: started\n",
      "  Running setup.py bdist_wheel for sklearn-randomforest: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-____rub2/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built sklearn-randomforest\u001b[0m\n",
      "\u001b[31mInstalling collected packages: sklearn-randomforest\u001b[0m\n",
      "\u001b[31mSuccessfully installed sklearn-randomforest-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.0.3 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:35,329 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:35,342 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"hyperparameters\": {},\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-04-08-03-12-08-484\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"log_level\": 20,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"num_gpus\": 0,\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"ethwe\",\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-029880428228/sagemaker-scikit-learn-2019-04-08-03-12-08-484/source/sourcedir.tar.gz\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"module_name\": \"sklearn-randomforest\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn-randomforest.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-2-029880428228/sagemaker-scikit-learn-2019-04-08-03-12-08-484/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=sklearn-randomforest\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=sklearn-randomforest.py\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-scikit-learn-2019-04-08-03-12-08-484\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-029880428228/sagemaker-scikit-learn-2019-04-08-03-12-08-484/source/sourcedir.tar.gz\",\"module_name\":\"sklearn-randomforest\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"sklearn-randomforest.py\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m sklearn-randomforest\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\u001b[0m\n",
      "\u001b[31m2019-04-08 03:14:36,903 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-04-08 03:14:44 Completed - Training job completed\n",
      "Billable seconds: 23\n"
     ]
    }
   ],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained model to make inference requests <a class=\"anchor\" id=\"inference\"></a>\n",
    "\n",
    "### Deploy the model <a class=\"anchor\" id=\"deploy\"></a>\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count and instance type. \n",
    "\n",
    "This predictor object will deploy the END POINT in AWS SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2019-04-08-03-12-08-484\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-scikit-learn-2019-04-08-03-12-08-484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction <a class=\"anchor\" id=\"prediction_request\"></a>\n",
    "\n",
    "In order to do some predictions, we'll extract some of the data we used for training and do predictions against it. This is, of course, bad statistical practice, but a good way to see how the mechanism works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data for testing the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ec2-user/SageMaker/data/DataForModeling.csv')\n",
    "df = df[:50]\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    60,   8450,      7,      5,   2003,   2003,    706,      0,\n",
       "           150,    856,    856,    854,      0,   1710,      1,      0,\n",
       "             2,      1,      3,      1,      8,      0,      2,    548,\n",
       "             0,     61,      0,      0,      0,      0,      0,      2,\n",
       "          2008, 208500]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the data, into features and dependant variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SalePrice\" in df.columns:\n",
    "    yData = df.SalePrice\n",
    "    del df[\"SalePrice\"]\n",
    "xData = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(xData,yData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Verify some of the loaded data and ensure it does not contain the home price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  20, 7560,    5,    6, 1958, 1965,  504,    0,  525, 1029, 1339,\n",
       "          0,    0, 1339,    0,    0,    1,    0,    3,    1,    6,    0,\n",
       "          1,  294,    0,    0,    0,    0,    0,    0,    0,    5, 2009])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('/home/ec2-user/SageMaker/data/DataForModeling.csv')\n",
    "X_test.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pass the values to the predictor object and obtain home prices and compared them against the real value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111400.  141000.  210350.  149097.5  77540.  140886.   88380.  285390.\n",
      " 181950.  153450.  129590.  154700.  146050. ]\n",
      "[118000 139000 208500 149350  68500 144000  82000 277500 129900 140000\n",
      " 129500 153000 145000]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(X_test))\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the End Point\n",
    "This will be use to set a Lambda function with this code to make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111400.0, 141000.0]\n",
      "190,7420,5,6,1939,1950,851,0,140,991,1077,0,0,1077,1,0,1,0,2,2,5,2,1,205,0,4,0,0,0,0,0,1,2008\n",
      "20,7560,5,6,1958,1965,504,0,525,1029,1339,0,0,1339,0,0,1,0,3,1,6,0,1,294,0,0,0,0,0,0,0,5,2009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtime= boto3.client('runtime.sagemaker')\n",
    "linear_endpoint='sagemaker-scikit-learn-2019-04-08-03-12-08-484'\n",
    "payload_file = io.StringIO()\n",
    "X_test[:2].to_csv(payload_file, header = None, index = None)\n",
    "\n",
    "#the Next line is use for testing\n",
    "#testLoad= \"20,7560,5,6,1958,1965,504,0,525,1029,1339,0,0,1339,0,0,1,0,3,1,6,0,1,294,0,0,0,0,0,0,0,5,2009\" + \"\\n\" + \"20,7560,5,6,1958,1965,504,0,525,1029,1339,0,0,1339,0,0,1,0,3,1,6,0,1,294,0,0,0,0,0,0,0,5,2009\"\n",
    "            \n",
    "#payload = X_test.values[1]\n",
    "response = runtime.invoke_endpoint(EndpointName=linear_endpoint,\n",
    "                                   ContentType = 'text/csv',\n",
    "                                   Body= payload_file.getvalue())\n",
    "import json\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n",
    "print(payload_file.getvalue())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint cleanup <a class=\"anchor\" id=\"endpoint_cleanup\"></a>\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-scikit-learn-2019-04-08-03-12-08-484\n"
     ]
    }
   ],
   "source": [
    "sklearn.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix Script to be used by Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Scikit-learn script to train with <a class=\"anchor\" id=\"create_sklearn_script\"></a>\n",
    "SageMaker can now run a scikit-learn script using the `SKLearn` estimator.\n",
    "\n",
    "```python\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train) ]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    raw_data = [ pd.read_csv(file,  engine=\"python\") for file in input_files ]\n",
    "    train_data = pd.concat(raw_data)\n",
    "    \n",
    "    if \"SalePrice\" in train_data.columns:\n",
    "        yData = train_data.SalePrice\n",
    "        del train_data[\"SalePrice\"]\n",
    "    \n",
    "    xData = train_data\n",
    "    # labels are in the first column\n",
    "    #train_y = train_data.ix[:,0]\n",
    "    #train_X = train_data.ix[:,1:]\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(all_X,all_y)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Here we support a single hyperparameter, 'max_leaf_nodes'. Note that you can add as many\n",
    "    # as your training my require in the ArgumentParser above.\n",
    "   \n",
    "    # Now use scikit-learn's decision tree classifier to train the model.\n",
    "    rf=RandomForestRegressor()\n",
    "    rf.fit(xData,yData)\n",
    "\n",
    "    # Print the coefficients of the trained classifier, and save the coefficients\n",
    "    joblib.dump(rf, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "    \n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    rf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return rf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
